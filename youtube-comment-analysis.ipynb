{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import credentials\n",
    "import time\n",
    "\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing key from separate python file\n",
    "\n",
    "key = credentials.youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing data\n",
    "\n",
    "path = 'c:/Users/Diego/GitHub/gothamchess_data_stats.csv'\n",
    "import_df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_values(comment) : #function to parse comments and return sentiment scores\n",
    "    sentiment = sentiment_analyzer.polarity_scores(comment)\n",
    "\n",
    "    pos = sentiment['pos']\n",
    "    neu = sentiment['neu']\n",
    "    neg = sentiment['neg']\n",
    "    comp = sentiment['compound']\n",
    "\n",
    "    return pos, neu, neg, comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(df) : #function to make api call and iterate over video ids in url and collect video's comments\n",
    "\n",
    "    for index, row in import_df.iterrows():\n",
    "        video_id = row['video_id']\n",
    "        pageToken = ''\n",
    "        \n",
    "        while 1:\n",
    "            url_comments = f'https://youtube.googleapis.com/youtube/v3/commentThreads?part=snippet&maxResults=100&videoId={video_id}&key={key}&order=relevance&{pageToken}'\n",
    "            comment_api = requests.get(url_comments).json()\n",
    "        \n",
    "            time.sleep(1)\n",
    "            for comments in comment_api['items'] :\n",
    "                comment = comments['snippet']['topLevelComment']['snippet']['textDisplay']\n",
    "\n",
    "                pos, neu, neg, comp = get_sentiment_values(comment) #parsing comment to grab sentiment values\n",
    "\n",
    "                temp_df = pd.DataFrame({\n",
    "                    'video_id' : [video_id],\n",
    "                    'positive_value' : [pos],\n",
    "                    'neutral_value' : [neu],\n",
    "                    'negative_value' : [neg],\n",
    "                    'compound' : [comp]})\n",
    "\n",
    "                df = pd.concat([df, temp_df], ignore_index=True)\n",
    "\n",
    "            try: \n",
    "                if comment_api['nextPageToken'] != None: #as long as 'nextPageToken' is not blank the loop will continue and grab string to be used in next api call\n",
    "                    pageToken = 'pageToken=' + comment_api['nextPageToken'] \n",
    "            except: #once 'nextPageToken' is blank the loop will break\n",
    "                break\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['video_id','positive_value','neutral_value','negative_value','compound'])\n",
    "\n",
    "dfn = get_sentiment(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_formatting(table) : #function to parse dataframe and apply formatting\n",
    "    avg = table.groupby(['video_id']).mean().round(2) #grouping values by video and rounding\n",
    "    join_df = import_df.join(avg, on=['video_id'], how='left') #left join to dataframe that was imported\n",
    "    join_df = join_df.drop(columns=['Unnamed: 0']) #dropping unnecessary column - will need to fix\n",
    "\n",
    "    return join_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_frame = df_formatting(dfn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_frame"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5238573367df39f7286bb46f9ff5f08f63a01a80960060ce41e3c79b190280fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
